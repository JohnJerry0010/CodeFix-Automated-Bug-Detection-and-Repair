{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set dataset path\n",
    "bugsinpy_path = \"C:/Users/hp/BugsInPy/projects\"  # UPDATE with the actual path\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Path exists!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "bugsinpy_path = \"C:/Users/hp/BugsInPy/projects\"  # Update this with your correct path\n",
    "\n",
    "if os.path.exists(bugsinpy_path):\n",
    "    print(\" Path exists!\")\n",
    "else:\n",
    "    print(\" Path does not exist. Check the folder location.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Projects: 100%|██████████| 17/17 [00:08<00:00,  2.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   project bug_id                                               code  label\n",
      "0  ansible      1  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "1  ansible      1  diff --git a/lib/ansible/galaxy/collection.py ...      0\n",
      "2  ansible     10  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "3  ansible     10  diff --git a/lib/ansible/modules/system/pamd.p...      0\n",
      "4  ansible     11  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def load_bugsinpy_data(base_path):\n",
    "    data = []\n",
    "\n",
    "    for project in tqdm(os.listdir(base_path), desc=\"Processing Projects\"):\n",
    "        project_path = os.path.join(base_path, project)\n",
    "        bugs_path = os.path.join(project_path, \"bugs\")  # Buggy code location\n",
    "\n",
    "        if os.path.exists(bugs_path):\n",
    "            for bug_id in os.listdir(bugs_path):\n",
    "                bug_folder = os.path.join(bugs_path, bug_id)\n",
    "\n",
    "                bug_info_path = os.path.join(bug_folder, \"bug.info\")  # Contains bug details\n",
    "                bug_patch_path = os.path.join(bug_folder, \"bug_patch.txt\")  # Contains fixes\n",
    "\n",
    "                # Read buggy code details\n",
    "                if os.path.exists(bug_info_path):\n",
    "                    with open(bug_info_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        buggy_code = f.read()\n",
    "\n",
    "                    data.append({\"project\": project, \"bug_id\": bug_id, \"code\": buggy_code, \"label\": 1})  # Buggy\n",
    "\n",
    "                # Read fixed code details\n",
    "                if os.path.exists(bug_patch_path):\n",
    "                    with open(bug_patch_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        fixed_code = f.read()\n",
    "\n",
    "                    data.append({\"project\": project, \"bug_id\": bug_id, \"code\": fixed_code, \"label\": 0})  # Fixed\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load dataset\n",
    "df = load_bugsinpy_data(bugsinpy_path)\n",
    "\n",
    "# Display dataset sample\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    project bug_id                                               code  label\n",
      "0   ansible      1  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "1   ansible      1  diff --git a/lib/ansible/galaxy/collection.py ...      0\n",
      "2   ansible     10  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "3   ansible     10  diff --git a/lib/ansible/modules/system/pamd.p...      0\n",
      "4   ansible     11  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "5   ansible     11  diff --git a/lib/ansible/modules/network/ios/i...      0\n",
      "6   ansible     12  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "7   ansible     12  diff --git a/lib/ansible/plugins/lookup/env.py...      0\n",
      "8   ansible     13  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "9   ansible     13  diff --git a/lib/ansible/cli/galaxy.py b/lib/a...      0\n",
      "10  ansible     14  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "11  ansible     14  diff --git a/lib/ansible/galaxy/api.py b/lib/a...      0\n",
      "12  ansible     15  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "13  ansible     15  diff --git a/lib/ansible/modules/network/eos/e...      0\n",
      "14  ansible     16  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "15  ansible     16  diff --git a/lib/ansible/module_utils/facts/ha...      0\n",
      "16  ansible     17  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "17  ansible     17  diff --git a/lib/ansible/module_utils/facts/ha...      0\n",
      "18  ansible     18  python_version=\"3.6.9\"\\npythonpath=\"ansible/bu...      1\n",
      "19  ansible     18  diff --git a/lib/ansible/cli/galaxy.py b/lib/a...      0\n"
     ]
    }
   ],
   "source": [
    "print(df.head(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"bugsinpy_dataset.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV file saved as: bugsinpy_dataset.csv\n"
     ]
    }
   ],
   "source": [
    "# Convert to DataFrame\n",
    "df = pd.DataFrame(df)\n",
    "\n",
    "csv_filename = \"bugsinpy_dataset.csv\"\n",
    "df.to_csv(csv_filename, index=False)\n",
    "\n",
    "print(f\"CSV file saved as: {csv_filename}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing Projects: 100%|██████████| 17/17 [00:00<00:00, 55.09it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset saved as: bugsinpy_dataset.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Set dataset path (UPDATE with the actual path)\n",
    "bugsinpy_path = \"C:/Users/hp/BugsInPy/projects\"\n",
    "csv_filename = \"bugsinpy_dataset.csv\"  # Name of the saved CSV file\n",
    "\n",
    "def load_bugsinpy_data(base_path):\n",
    "    data = []\n",
    "\n",
    "    for project in tqdm(os.listdir(base_path), desc=\"Processing Projects\"):\n",
    "        project_path = os.path.join(base_path, project)\n",
    "        bugs_path = os.path.join(project_path, \"bugs\")  # Buggy code location\n",
    "\n",
    "        if os.path.exists(bugs_path):\n",
    "            for bug_id in os.listdir(bugs_path):\n",
    "                bug_folder = os.path.join(bugs_path, bug_id)\n",
    "\n",
    "                bug_info_path = os.path.join(bug_folder, \"bug.info\")  # Buggy code\n",
    "                bug_patch_path = os.path.join(bug_folder, \"bug_patch.txt\")  # Fixed code\n",
    "\n",
    "                # Read buggy code details\n",
    "                if os.path.exists(bug_info_path):\n",
    "                    with open(bug_info_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        buggy_code = f.read()\n",
    "\n",
    "                    data.append({\"project\": project, \"bug_id\": bug_id, \"code\": buggy_code, \"label\": 1})  # Buggy\n",
    "\n",
    "                # Read fixed code details\n",
    "                if os.path.exists(bug_patch_path):\n",
    "                    with open(bug_patch_path, \"r\", encoding=\"utf-8\") as f:\n",
    "                        fixed_code = f.read()\n",
    "\n",
    "                    data.append({\"project\": project, \"bug_id\": bug_id, \"code\": fixed_code, \"label\": 0})  # Fixed\n",
    "\n",
    "    return pd.DataFrame(data)\n",
    "\n",
    "# Load dataset\n",
    "df = load_bugsinpy_data(bugsinpy_path)\n",
    "\n",
    "# Save dataset as CSV in the local system\n",
    "df.to_csv(csv_filename, index=False, encoding=\"utf-8\")\n",
    "\n",
    "print(f\"Dataset saved as: {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "js_all=json.load(open(\"C:/Users/hp/CodeXGLUE/Code-Code/Defect-detection/dataset/function.json\"))\n",
    "\n",
    "train_index=set()\n",
    "valid_index=set()\n",
    "test_index=set()\n",
    "\n",
    "with open('C:/Users/hp/CodeXGLUE/Code-Code/Defect-detection/dataset/train.txt') as f:\n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        train_index.add(int(line))\n",
    "                    \n",
    "with open('C:/Users/hp/CodeXGLUE/Code-Code/Defect-detection/dataset/valid.txt') as f:\n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        valid_index.add(int(line))\n",
    "        \n",
    "with open('C:/Users/hp/CodeXGLUE/Code-Code/Defect-detection/dataset/test.txt') as f:\n",
    "    for line in f:\n",
    "        line=line.strip()\n",
    "        test_index.add(int(line))\n",
    "\n",
    "        \n",
    "        \n",
    "with open('train.jsonl','w') as f:\n",
    "    for idx,js in enumerate(js_all):\n",
    "        if idx in train_index:\n",
    "            js['idx']=idx\n",
    "            f.write(json.dumps(js)+'\\n')\n",
    "            \n",
    "with open('valid.jsonl','w') as f:\n",
    "    for idx,js in enumerate(js_all):\n",
    "        if idx in valid_index:\n",
    "            js['idx']=idx\n",
    "            f.write(json.dumps(js)+'\\n')\n",
    "            \n",
    "with open('test.jsonl','w') as f:\n",
    "    for idx,js in enumerate(js_all):\n",
    "        if idx in test_index:\n",
    "            js['idx']=idx\n",
    "            f.write(json.dumps(js)+'\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\hp\\anaconda3\\lib\\site-packages (4.46.3)\n",
      "Requirement already satisfied: filelock in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (3.9.0)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.23.2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.26.3)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (1.24.3)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (24.2)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (6.0)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2022.7.9)\n",
      "Requirement already satisfied: requests in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (2.32.3)\n",
      "Requirement already satisfied: tokenizers<0.21,>=0.20 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.20.3)\n",
      "Requirement already satisfied: safetensors>=0.4.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (0.4.5)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from transformers) (4.67.1)\n",
      "Requirement already satisfied: fsspec>=2023.5.0 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (2024.9.0)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from huggingface-hub<1.0,>=0.23.2->transformers) (4.12.2)\n",
      "Requirement already satisfied: colorama in c:\\users\\hp\\anaconda3\\lib\\site-packages (from tqdm>=4.27->transformers) (0.4.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.4.0)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\hp\\anaconda3\\lib\\site-packages (from requests->transformers) (2025.1.31)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install transformers\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
